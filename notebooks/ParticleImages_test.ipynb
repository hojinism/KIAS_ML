{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 13:11:43.461718: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-05 13:11:43.931947: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np; np.random.seed(1337)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, SeparableConv2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import h5py\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model parameters\n",
    "lr_init     = 1.e-3    # Initial learning rate  \n",
    "batch_size  = 64       # Training batch size\n",
    "train_size  = 1024*100     # Training size\n",
    "valid_size  = 1024     # Validation size\n",
    "test_size   = 1024*5     # Test size\n",
    "epochs      = 20       # Number of epochs\n",
    "doGPU       = True     # Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 13:11:44.890336: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:11:44.907469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:11:44.907700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:11:45.401774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:11:45.401974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:11:45.402121: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:11:45.402240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6605 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "if doGPU:\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    from tensorflow.compat.v1.keras.backend import set_session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image data\n",
    "img_rows, img_cols, nb_channels = 32, 32, 2        \n",
    "input_dir = 'Particle_Images/data'\n",
    "decays = ['SinglePhotonPt50_IMGCROPS_n249k_RHv1', 'SingleElectronPt50_IMGCROPS_n249k_RHv1']\n",
    "\n",
    "def load_data(decays, start, stop):\n",
    "    global input_dir\n",
    "    dsets = [h5py.File('%s/%s.hdf5'%(input_dir,decay)) for decay in decays]\n",
    "    X = np.concatenate([dset['/X'][start:stop] for dset in dsets])\n",
    "    y = np.concatenate([dset['/y'][start:stop] for dset in dsets])\n",
    "    assert len(X) == len(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training / validation / test sets\n",
    "# Set range of training set\n",
    "train_start, train_stop = 0, train_size\n",
    "assert train_stop > train_start\n",
    "assert (len(decays)*train_size) % batch_size == 0\n",
    "X_train, y_train = load_data(decays,train_start,train_stop)\n",
    "\n",
    "# Set range of validation set\n",
    "valid_start, valid_stop = 160000, 160000+valid_size\n",
    "assert valid_stop  >  valid_start\n",
    "assert valid_start >= train_stop\n",
    "X_valid, y_valid = load_data(decays,valid_start,valid_stop)\n",
    "\n",
    "# Set range of test set\n",
    "test_start, test_stop = 204800, 204800+test_size\n",
    "assert test_stop  >  test_start\n",
    "assert test_start >= valid_stop\n",
    "X_test, y_test = load_data(decays,test_start,test_stop)\n",
    "\n",
    "samples_requested = len(decays) * (train_size + valid_size + test_size)\n",
    "samples_available = len(y_train) + len(y_valid) + len(y_test)\n",
    "assert samples_requested == samples_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot sample of traiing images\n",
    "plt.figure(1)\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[1,:,:,0])\n",
    "plt.title(\"Channel 0: Energy\")  # Energy\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1,:,:,1])\n",
    "plt.title(\"Channel 1: Time\")  # Time\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choij/miniconda3/envs/kias/lib/python3.11/site-packages/keras/applications/resnet.py:159: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 2 input channels.\n",
      "  input_shape = imagenet_utils.obtain_input_shape(\n",
      "2023-07-05 13:11:54.491833: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:11:54.492048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:11:54.492193: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:11:54.492424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:11:54.492589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:11:54.492728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:11:54.492904: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:11:54.493046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:11:54.493156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6605 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 38, 38, 2)    0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 16, 16, 64)   6336        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          524544      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            257         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,109,377\n",
      "Trainable params: 24,056,257\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    input_shape=(32, 32, 2)\n",
    ")\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=lr_init), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 13:12:09.193231: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8901\n",
      "2023-07-05 13:12:10.002665: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f19106b8240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-05 13:12:10.002702: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 2070 SUPER, Compute Capability 7.5\n",
      "2023-07-05 13:12:10.005735: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-05 13:12:10.101645: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-07-05 13:12:10.494900: W tensorflow/tsl/framework/bfc_allocator.cc:366] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2023-07-05 13:12:13.509578: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-05 13:12:13.509645: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-05 13:12:17.876189: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-05 13:12:17.876257: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3200 [==============================] - 128s 33ms/step - loss: 0.6710 - accuracy: 0.5953 - val_loss: 0.6584 - val_accuracy: 0.6104 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "3200/3200 [==============================] - 105s 33ms/step - loss: 0.6407 - accuracy: 0.6356 - val_loss: 0.6275 - val_accuracy: 0.6611 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "3200/3200 [==============================] - 102s 32ms/step - loss: 0.6167 - accuracy: 0.6652 - val_loss: 0.6257 - val_accuracy: 0.6626 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "3200/3200 [==============================] - 102s 32ms/step - loss: 0.6101 - accuracy: 0.6727 - val_loss: 0.6371 - val_accuracy: 0.6421 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "3200/3200 [==============================] - 103s 32ms/step - loss: 0.5913 - accuracy: 0.6921 - val_loss: 0.5901 - val_accuracy: 0.6904 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "3200/3200 [==============================] - 103s 32ms/step - loss: 0.5829 - accuracy: 0.6987 - val_loss: 0.5912 - val_accuracy: 0.6899 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "3200/3200 [==============================] - 103s 32ms/step - loss: 0.5771 - accuracy: 0.7037 - val_loss: 0.5793 - val_accuracy: 0.7051 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "3200/3200 [==============================] - 103s 32ms/step - loss: 0.5718 - accuracy: 0.7095 - val_loss: 0.6047 - val_accuracy: 0.6855 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "3200/3200 [==============================] - 104s 32ms/step - loss: 0.5680 - accuracy: 0.7121 - val_loss: 0.5907 - val_accuracy: 0.6929 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "3200/3200 [==============================] - 105s 33ms/step - loss: 0.5510 - accuracy: 0.7251 - val_loss: 0.5771 - val_accuracy: 0.7100 - lr: 2.0000e-04\n",
      "Epoch 11/20\n",
      "3200/3200 [==============================] - 102s 32ms/step - loss: 0.5460 - accuracy: 0.7291 - val_loss: 0.5735 - val_accuracy: 0.7129 - lr: 2.0000e-04\n",
      "Epoch 12/20\n",
      "3200/3200 [==============================] - 103s 32ms/step - loss: 0.5423 - accuracy: 0.7318 - val_loss: 0.5687 - val_accuracy: 0.7192 - lr: 2.0000e-04\n",
      "Epoch 13/20\n",
      "3200/3200 [==============================] - 102s 32ms/step - loss: 0.5398 - accuracy: 0.7336 - val_loss: 0.5750 - val_accuracy: 0.7134 - lr: 2.0000e-04\n",
      "Epoch 14/20\n",
      "3200/3200 [==============================] - 103s 32ms/step - loss: 0.5372 - accuracy: 0.7356 - val_loss: 0.5782 - val_accuracy: 0.7109 - lr: 2.0000e-04\n",
      "Epoch 15/20\n",
      "3200/3200 [==============================] - 103s 32ms/step - loss: 0.5302 - accuracy: 0.7397 - val_loss: 0.5754 - val_accuracy: 0.7144 - lr: 4.0000e-05\n",
      "Epoch 16/20\n",
      "3200/3200 [==============================] - 101s 32ms/step - loss: 0.5283 - accuracy: 0.7410 - val_loss: 0.5757 - val_accuracy: 0.7100 - lr: 4.0000e-05\n",
      "Epoch 17/20\n",
      "3200/3200 [==============================] - 103s 32ms/step - loss: 0.5258 - accuracy: 0.7429 - val_loss: 0.5757 - val_accuracy: 0.7129 - lr: 8.0000e-06\n",
      "Epoch 18/20\n",
      "3200/3200 [==============================] - 103s 32ms/step - loss: 0.5259 - accuracy: 0.7429 - val_loss: 0.5760 - val_accuracy: 0.7114 - lr: 8.0000e-06\n",
      "Epoch 19/20\n",
      "3200/3200 [==============================] - 100s 31ms/step - loss: 0.5253 - accuracy: 0.7436 - val_loss: 0.5764 - val_accuracy: 0.7104 - lr: 1.6000e-06\n",
      "Epoch 20/20\n",
      "3200/3200 [==============================] - 103s 32ms/step - loss: 0.5252 - accuracy: 0.7435 - val_loss: 0.5760 - val_accuracy: 0.7104 - lr: 1.6000e-06\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1.e-6)\n",
    "checkpoint_filepath=\"/checkpoints\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"./checkpoints\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True\n",
    ")\n",
    "\n",
    "history=model.fit(X_train, y_train,\\\n",
    "        batch_size=batch_size,\\\n",
    "        epochs=epochs,\\\n",
    "        validation_data=(X_valid, y_valid),\\\n",
    "        callbacks=[reduce_lr, checkpoint_callback],\\\n",
    "        verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpoints",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# evaluate the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mload_weights(\u001b[39m\"\u001b[39;49m\u001b[39m./checkpoints\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_valid, y_valid, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mValidation loss / accuracy: \u001b[39m\u001b[39m%0.4f\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m%0.4f\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m(score[\u001b[39m0\u001b[39m], score[\u001b[39m1\u001b[39m]))\n",
      "File \u001b[0;32m~/miniconda3/envs/kias/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/kias/lib/python3.11/site-packages/tensorflow/python/training/py_checkpoint_reader.py:31\u001b[0m, in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     27\u001b[0m error_message \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(e)\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mnot found in checkpoint\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m error_message \u001b[39mor\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mFailed to find any \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     30\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmatching files for\u001b[39m\u001b[39m'\u001b[39m) \u001b[39min\u001b[39;00m error_message:\n\u001b[0;32m---> 31\u001b[0m   \u001b[39mraise\u001b[39;00m errors_impl\u001b[39m.\u001b[39mNotFoundError(\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, error_message)\n\u001b[1;32m     32\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mSliced checkpoints are not supported\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m error_message \u001b[39mor\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mData type \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     34\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mnot \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[39m'\u001b[39m\u001b[39msupported\u001b[39m\u001b[39m'\u001b[39m) \u001b[39min\u001b[39;00m error_message:\n\u001b[1;32m     36\u001b[0m   \u001b[39mraise\u001b[39;00m errors_impl\u001b[39m.\u001b[39mUnimplementedError(\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, error_message)\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpoints"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "model.load_weights(\"./checkpoints\")\n",
    "score = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('\\nValidation loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
    "y_pred = model.predict(X_valid)\n",
    "fpr, tpr, _ = roc_curve(y_valid, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Validation ROC AUC:', roc_auc)\n",
    "\n",
    "# Evaluate on test set\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('\\nTest loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
    "y_pred = model.predict(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Test ROC AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fpr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[39m.\u001b[39mplot([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m], [\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mk--\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[39m#plt.legend(loc=2, prop={'size': 15})\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plt\u001b[39m.\u001b[39mplot(fpr, tpr, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mModel 1 (ROC-AUC = \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(roc_auc))\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mFalse positive rate\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mTrue positive rate\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fpr' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "#plt.legend(loc=2, prop={'size': 15})\n",
    "plt.plot(fpr, tpr, label='Model 1 (ROC-AUC = {:.3f})'.format(roc_auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
