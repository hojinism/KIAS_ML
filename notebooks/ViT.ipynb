{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 13:48:04.859144: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-05 13:48:05.389863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-05 13:48:06.120413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:48:06.136421: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:48:06.136656: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:48:06.594760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:48:06.594952: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:48:06.595090: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 13:48:06.595209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 200 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choij/miniconda3/envs/kias/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Dense, Activation \n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras import regularizers \n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 32, 32, 2)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "filename = \"./Particle_Images/data/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\"\n",
    "data1 = h5py.File(filename, \"r\")\n",
    "Y1 = data1[\"y\"][:200000]\n",
    "X1 = data1[\"X\"][:200000]\n",
    "filename = \"./Particle_Images/data/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\"\n",
    "data0 = h5py.File(filename, \"r\")\n",
    "Y0 = data0[\"y\"][:200000]\n",
    "X0 = data0[\"X\"][:200000]\n",
    "X_final = np.concatenate((X0[:], X1[:]), axis=0)\n",
    "Y_final = np.concatenate((Y0[:], Y1[:]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 32, 32, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (320000, 32, 32, 1) - y_train shape: (320000,)\n",
      "x_test shape: (80000, 32, 32, 1) - y_test shape: (80000,)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 2) #Using the Hit-Energy channel only\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X_final[:, :, :, 0:1],\n",
    "    Y_final,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "    \n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 128\n",
    "num_epochs = 20\n",
    "image_size = 32 # We'll resize input images to this size\n",
    "patch_size = 4  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 32\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [256,128]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 12:40:47.466666: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 12:40:47.466986: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 12:40:47.467206: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 12:40:47.467603: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 12:40:47.467838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 12:40:47.468053: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 12:40:47.468323: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 12:40:47.468544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-05 12:40:47.468722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5521 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        #layers.Resizing(image_size, image_size),\n",
    "        #layers.RandomFlip(\"horizontal\"),\n",
    "        #layers.RandomRotation(factor=0.02),\n",
    "        #layers.RandomZoom(\n",
    "         #   height_factor = 0.2, width_factor = 0.2\n",
    "        #),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 32 X 32\n",
      "Patch size: 4 X 4\n",
      "Patches per image: 64\n",
      "Elements per patch: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "image = x_train[0,:,:,0]\n",
    "plt.imshow(image.astype(\"float32\"))\n",
    "#plt.axis(\"off\")\n",
    "\n",
    "patches = Patches(patch_size)(x_train[0:1,:,:,0:1])\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size))\n",
    "    plt.imshow(patch_img.numpy().astype(\"float32\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "        \n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(1)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2382/2382 [==============================] - 85s 34ms/step - loss: 0.6966 - accuracy: 0.4995 - mae: 0.5253 - val_loss: 0.6933 - val_accuracy: 0.5001 - val_mae: 0.4997\n",
      "Epoch 2/20\n",
      "2382/2382 [==============================] - 79s 33ms/step - loss: 0.6477 - accuracy: 0.5810 - mae: 0.6720 - val_loss: 0.5898 - val_accuracy: 0.6652 - val_mae: 0.7977\n",
      "Epoch 3/20\n",
      "2382/2382 [==============================] - 79s 33ms/step - loss: 0.5962 - accuracy: 0.6652 - mae: 0.8207 - val_loss: 0.6002 - val_accuracy: 0.6771 - val_mae: 0.9954\n",
      "Epoch 4/20\n",
      "2382/2382 [==============================] - 79s 33ms/step - loss: 0.5859 - accuracy: 0.6790 - mae: 0.8534 - val_loss: 0.6234 - val_accuracy: 0.6956 - val_mae: 0.7257\n",
      "Epoch 5/20\n",
      "2382/2382 [==============================] - 79s 33ms/step - loss: 0.5815 - accuracy: 0.6844 - mae: 0.8697 - val_loss: 0.5657 - val_accuracy: 0.7041 - val_mae: 0.9123\n",
      "Epoch 6/20\n",
      "2382/2382 [==============================] - 92s 39ms/step - loss: 0.5798 - accuracy: 0.6852 - mae: 0.8751 - val_loss: 0.5662 - val_accuracy: 0.6946 - val_mae: 0.7698\n",
      "Epoch 7/20\n",
      "2382/2382 [==============================] - 112s 47ms/step - loss: 0.5772 - accuracy: 0.6887 - mae: 0.8845 - val_loss: 0.5640 - val_accuracy: 0.7068 - val_mae: 0.9743\n",
      "Epoch 8/20\n",
      "2382/2382 [==============================] - 113s 47ms/step - loss: 0.5773 - accuracy: 0.6885 - mae: 0.8874 - val_loss: 0.5775 - val_accuracy: 0.7080 - val_mae: 0.6540\n",
      "Epoch 9/20\n",
      "2382/2382 [==============================] - 99s 41ms/step - loss: 0.5762 - accuracy: 0.6896 - mae: 0.8881 - val_loss: 0.5666 - val_accuracy: 0.7087 - val_mae: 0.8237\n",
      "Epoch 10/20\n",
      "2382/2382 [==============================] - 79s 33ms/step - loss: 0.5760 - accuracy: 0.6897 - mae: 0.8897 - val_loss: 0.5763 - val_accuracy: 0.6800 - val_mae: 1.0527\n",
      "Epoch 11/20\n",
      "2382/2382 [==============================] - 79s 33ms/step - loss: 0.5750 - accuracy: 0.6910 - mae: 0.8943 - val_loss: 0.5656 - val_accuracy: 0.6975 - val_mae: 0.9988\n",
      "Epoch 12/20\n",
      "2382/2382 [==============================] - 79s 33ms/step - loss: 0.5753 - accuracy: 0.6909 - mae: 0.8945 - val_loss: 0.5734 - val_accuracy: 0.6894 - val_mae: 0.7205\n",
      "Epoch 13/20\n",
      "2382/2382 [==============================] - 79s 33ms/step - loss: 0.5748 - accuracy: 0.6910 - mae: 0.8926 - val_loss: 0.5623 - val_accuracy: 0.7127 - val_mae: 0.8217\n",
      "Epoch 14/20\n",
      " 301/2382 [==>...........................] - ETA: 1:05 - loss: 0.5722 - accuracy: 0.6951 - mae: 0.8986"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 42\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39mreturn\u001b[39;00m history\n\u001b[1;32m     41\u001b[0m vit_classifier \u001b[39m=\u001b[39m create_vit_classifier()\n\u001b[0;32m---> 42\u001b[0m history \u001b[39m=\u001b[39m run_experiment(vit_classifier)\n",
      "Cell \u001b[0;32mIn[14], line 24\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     16\u001b[0m checkpoint_filepath \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/tmp/checkpoint\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m checkpoint_callback \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\n\u001b[1;32m     18\u001b[0m     checkpoint_filepath,\n\u001b[1;32m     19\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m     save_weights_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     25\u001b[0m     x\u001b[39m=\u001b[39;49mx_train,\n\u001b[1;32m     26\u001b[0m     y\u001b[39m=\u001b[39;49my_train,\n\u001b[1;32m     27\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     28\u001b[0m     epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m     29\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m,\n\u001b[1;32m     30\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[checkpoint_callback],\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m model\u001b[39m.\u001b[39mload_weights(checkpoint_filepath)\n\u001b[1;32m     34\u001b[0m _, accuracy, top_5_accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_test, y_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/kias/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/kias/lib/python3.11/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/kias/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/kias/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/kias/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/kias/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/kias/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/kias/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/kias/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,#keras.optimizers.Adam(lr=0.001),\n",
    "        loss= keras.losses.BinaryCrossentropy(from_logits=True),#'binary_crossentropy',\n",
    "        #loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'mae'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    #print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "vit_classifier = create_vit_classifier()\n",
    "history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
